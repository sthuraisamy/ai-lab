{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_vals = [(re.compile(r'@\\w+'), ''),\n",
    "                          (re.compile(r'http\\S+'), '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_set(data_filename):\n",
    "    '''function to read dataset and print some information about the dataset'''\n",
    "    # read csv file into dataframe\n",
    "    data_df = pd.read_csv(\n",
    "        data_filename, delimiter=\",\", encoding=\"utf-8\")\n",
    "\n",
    "    # print the info of twitter data frame\n",
    "    print(data_df.head())\n",
    "    print(data_df.shape)\n",
    "    print(data_df.columns)\n",
    "    print(data_df.isnull().sum())\n",
    "\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_token_cleanup(text, replace_vals):\n",
    "    '''function to pre-process the tweets'''\n",
    "    text = text.lower()  # convert to lower case\n",
    "\n",
    "    # text = replace_with(text, [('&amp;', 'and'), ('&gt;', '>'), ('&lt;', '<')])\n",
    "    for replace in replace_vals:\n",
    "        text = re.sub(replace[0], replace[1], text)\n",
    "\n",
    "    text = text.strip()  # remove leading and trailing whitespace\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(review_df):\n",
    "    '''function to clean the reviews'''\n",
    "    review_df[\"review\"] = review_df[\"review\"].apply(pre_token_cleanup, args=(replace_vals,))\n",
    "    print(review_df.head())\n",
    "\n",
    "\n",
    "    return review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_wordcloud_common_words(review_df):\n",
    "    '''function to view the common words'''\n",
    "    # get the common words\n",
    "    all_words = ','.join(list(review_df['review'].values))\n",
    "    # print(all_words)\n",
    "\n",
    "    # view the word cloud\n",
    "    w_cloud = WordCloud(background_color='white', max_words=5000, width=600, height=300, contour_width=3, contour_color='steelblue')\n",
    "    w_cloud.generate(all_words)\n",
    "\n",
    "    w_cloud.to_file('wordcloud.png')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values_for_topic_analysis(review_df):\n",
    "    review_values = review_df[\"review\"].values\n",
    "    \n",
    "    return review_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_tokens(review_values):\n",
    "    '''function to get the word tokens'''\n",
    "    word_tokens = []\n",
    "    for review in review_values:\n",
    "        word_tokens.append(nltk.word_tokenize(review))\n",
    "\n",
    "    return word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from csv file into dataframe\n",
    "review_df = read_data_set('../data/k8_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize casings and clean up the tweets\n",
    "review_df = clean_reviews(review_df)\n",
    "\n",
    "# extract the review text values into a list for easier manipulation.\n",
    "review_values = get_values_for_topic_analysis(review_df)\n",
    "print(review_values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_wordcloud_common_words(review_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the reviews using NLTK\n",
    "review_word_tokens = get_word_tokens(review_values)\n",
    "print(review_word_tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using NLTK to get the parts of speech of the sentences\n",
    "review_sentences_postags = [nltk.pos_tag(sentence) for sentence in review_word_tokens]\n",
    "print(review_sentences_postags[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postags_with_nouns(review_sentences_postags):\n",
    "    '''function to get the pos tags with nouns'''\n",
    "    noun_tags = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "    postags_with_nouns = []\n",
    "    for sentence in review_sentences_postags:\n",
    "        postags_with_nouns.append([word for word, tag in sentence if tag in noun_tags])\n",
    "\n",
    "    return postags_with_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pos tags with nouns\n",
    "postags_with_nouns = get_postags_with_nouns(review_sentences_postags)\n",
    "print(postags_with_nouns[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postags_with_nouns_lemmed(postags_with_nouns):\n",
    "    '''function to get the pos tags with nouns lemmatized'''\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    postags_with_nouns_lemmed = []\n",
    "    for sentence in postags_with_nouns:\n",
    "        postags_with_nouns_lemmed.append([lemmatizer.lemmatize(word) for word in sentence])\n",
    "\n",
    "    return postags_with_nouns_lemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize the nouns\n",
    "postags_with_nouns_lemmed = get_postags_with_nouns_lemmed(postags_with_nouns)\n",
    "print(postags_with_nouns_lemmed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words_and_puncs(postags_with_nouns_lemmed):\n",
    "    '''function to remove stop words and punctuations'''\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "    postags_with_nouns_lemmed_no_stop_words = []\n",
    "    for sentence in postags_with_nouns_lemmed:\n",
    "        postags_with_nouns_lemmed_no_stop_words.append([word for word in sentence if word not in stop_words])\n",
    "\n",
    "    return postags_with_nouns_lemmed_no_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords and punctuation (if there are any).\n",
    "postags_with_nouns_lemmed_no_stop_words = remove_stop_words_and_puncs(postags_with_nouns_lemmed)\n",
    "print(postags_with_nouns_lemmed_no_stop_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_terms_for_topics_using_lda(postags_with_nouns_lemmed_no_stop_words, num_topics, alpha, passes, workers):\n",
    "    '''function to get the top terms for topics using LDA'''\n",
    "    # Create a dictionary representation of the documents.\n",
    "    dictionary = gensim.corpora.Dictionary(postags_with_nouns_lemmed_no_stop_words)\n",
    "    # Create a corpus from the bag of words.\n",
    "    corpus = [dictionary.doc2bow(sentence) for sentence in postags_with_nouns_lemmed_no_stop_words]\n",
    "    # Build the LDA model.\n",
    "    lda_model = gensim.models.LdaMulticore(corpus, num_topics=num_topics, id2word=dictionary, passes=passes, alpha=alpha, random_state=426, workers=workers)\n",
    "    \n",
    "    return lda_model, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics=12\n",
    "lda_model, dictionary = get_top_terms_for_topics_using_lda(postags_with_nouns_lemmed_no_stop_words, num_topics=num_topics, passes=20,alpha='symmetric', workers=3)\n",
    "\n",
    "print(lda_model.print_topics(num_topics=num_topics, num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coherence_score_using_lda(lda_model, dictionary, postags_with_nouns_lemmed_no_stop_words):\n",
    "    '''function to get the coherence score using LDA'''\n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, texts=postags_with_nouns_lemmed_no_stop_words, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    \n",
    "    return coherence_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_lda = get_coherence_score_using_lda(lda_model, dictionary, postags_with_nouns_lemmed_no_stop_words)\n",
    "print('Coherence score: ',coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coherence_score_for_multiple_topics(postags_with_nouns_lemmed_no_stop_words, num_topics_list):\n",
    "    '''function to get the coherence score for multiple topics'''\n",
    "    coherence_scores = []\n",
    "    for num_topics in num_topics_list:\n",
    "        \n",
    "        lda_model, dictionary = get_top_terms_for_topics_using_lda(postags_with_nouns_lemmed_no_stop_words, num_topics=num_topics, passes=30,alpha='symmetric', workers=5)\n",
    "        coherence_model_lda = get_coherence_score_using_lda(lda_model, dictionary, postags_with_nouns_lemmed_no_stop_words, num_topics)\n",
    "        coherence_scores.append(coherence_model_lda)\n",
    "    \n",
    "    return coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics_list = [5,6,7,8,9,10]\n",
    "coherence_scores = get_coherence_score_for_multiple_topics(postags_with_nouns_lemmed_no_stop_words, num_topics_list)\n",
    "print(coherence_scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model for better coherence score\n",
    "num_topics_for_better_coherence = num_topics_list[coherence_scores.index(max(coherence_scores))]\n",
    "print('Number of topics for better coherence score: ',num_topics_for_better_coherence)\n",
    "lda_model_v1, dictionary_v1 = get_top_terms_for_topics_using_lda(postags_with_nouns_lemmed_no_stop_words, num_topics=num_topics_for_better_coherence, passes=30,alpha='symmetric', workers=3)\n",
    "\n",
    "better_coherence_model_lda = get_coherence_score_using_lda(lda_model_v1, dictionary_v1, postags_with_nouns_lemmed_no_stop_words, num_topics_for_better_coherence)\n",
    "print('Better coherence model: ',better_coherence_model_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics_report(final_lda_model):\n",
    "    topic_words = {}\n",
    "    for idx, topic in final_lda_model.print_topics(-1):\n",
    "        temp = []\n",
    "        for item in topic.split('+'):\n",
    "            item_alpha = [letter for letter in item if letter.isalpha()]\n",
    "            temp.append(''.join(item_alpha))\n",
    "        topic_words[('Topic_'+str(idx+1))] = temp\n",
    "\n",
    "    topics_df = pd.DataFrame(topic_words)\n",
    "    topics_df.index = ['Word_'+str(i+1) for i in range(topics_df.shape[0])]\n",
    "    print(topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topics_report(lda_model_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1735d6009fec296ab35a6ff8d55b30cd473833f78753da2ded15c72f320c58f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
